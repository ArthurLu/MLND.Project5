{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worth exploring\n",
    "* Is SVM using OVR?\n",
    "* Mystery of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Project Origin: [Kaggle - Facebook V: Predicting Check Ins](https://www.kaggle.com/c/facebook-v-predicting-check-ins)\n",
    "* Description: Facebook and Kaggle launched a machine learning engineering competition of identifying the correct place for check ins. For giving a flavor of what it takes to work with real data, Facebook created an artificial world consisting of more than 100,000 places located in a 10 km by 10 km square and data was fabricated to resemble location signals coming from mobile devices.\n",
    "* Data sets:\n",
    "    * train.csv, test.csv\n",
    "        * row_id: id of the check-in event\n",
    "        * x y: coordinates\n",
    "        * accuracy: location accuracy \n",
    "        * time: timestamp\n",
    "        * place_id: id of the business (this is the target I'm  predicting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Goal: The goal is to predict a ranked list of place a person would like to check in to.\n",
    "* Proposed Solution:\n",
    "    * TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction is evaluated according to the [Mean Average Precision @3](https://www.kaggle.com/wiki/MeanAveragePrecision)  (MAP@3)\n",
    "\\begin{equation*}\n",
    "    MAP@3 = \\frac{1}{|U|} \\sum_{u=1}^{|U|} \\sum_{k=1}^{min(3,n)} P(k)\n",
    "\\end{equation*}\n",
    "where |U| is the number of check in events, P(k) is the precision at cutoff k, n is the number of predicted businesses.\n",
    "* MAP is chosen because the prediction would be a list of ranked place and the order of place matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For plotting\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Size of training data: {}'.format(df_train.shape)\n",
    "print 'Size of testing data: {}'.format(df_test.shape)\n",
    "print 'Columns of data: {}'.format(df_train.columns.values)\n",
    "print \"Description of training data: \\n\"\n",
    "print df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate\n",
    "* We can see that the check-ins are roughly uniformly distributed on the map.\n",
    "* Because the number of data is huge, only taking 1% of random sample to investigate the distribution of x and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=df_train.sample(frac=0.01), x='x',y='y',kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "* From the histogram of accuracy, we could know that majority of value is **under 200**.\n",
    "* The meaning of accuracy is still vague."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "ax1.set_title('Histogram of accuracy')\n",
    "ax1.set_xlabel('Accuracy')\n",
    "ax1.set_ylabel('Frequency')\n",
    "df_train['accuracy'].hist(bins=100,ax=ax1)\n",
    "ax2.set_title('Histogram of accuracy under 200')\n",
    "ax2.set_xlim((0,200))\n",
    "ax2.set_xlabel('Accuracy')\n",
    "ax2.set_ylabel('Frequency')\n",
    "df_train['accuracy'].hist(bins=100,ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Ids\n",
    "* From this section, we can know that there are a huge number of place ids and they are not uniformly distributed. This means that any algorithm which trains using a one vs all approach would not be the best choice on this dataset.\n",
    "* What is \"one vs all approach\"?\n",
    "    * This approach is training a single classifier per class for solving multiclass problems of n classes with the samples of that class as positive samples and all other samples as negatives. [( Reference-Wiki )](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of unique place id: {}, roughly {:.3f} % of traing data.\".format(len(df_train['place_id'].unique()), \n",
    "                                                                               len(df_train['place_id'].unique()) * 100.0 / df_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Place ids')\n",
    "df_train['place_id'].value_counts().head(5).plot.barh(title='Top 5 most common place ids', xlim=(0,2000)).invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Place ids')\n",
    "df_train['place_id'].value_counts().tail(5).plot.barh(title='Bottom 5 most uncommon place ids', xlim=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because the column of time is intentionally left vague without defining the unit of time, this section provides two methods to conclude the unit of time would be minute.\n",
    "* Method 1: Converted the time to week at the top 3 place in order to find in order to visualize the weekly cycles. [(Reference)](https://www.kaggle.com/jsab16/facebook-v-predicting-check-ins/on-time/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 1 place : 8772469670\n",
    "time = df_train[df_train['place_id']==8772469670]['time']\n",
    "time = time % (24*60*7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Week cycle of 1st place')\n",
    "time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 2 place : 1623394281\n",
    "time = df_train[df_train['place_id']==1623394281]['time']\n",
    "time = time % (24*60*7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Week cycle of 2nd place')\n",
    "time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 3 place : 1308450003\n",
    "time = df_train[df_train['place_id']==1308450003]['time']\n",
    "time = time % (24*60*7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Week cycle of 3nd place')\n",
    "time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Method 2: Used Fourier transform to extract the dominant frequency in order to find the period at the top 3 place. [(Reference)](https://www.kaggle.com/leonlu/facebook-v-predicting-check-ins/another-way-to-know-the-time-definition/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 1 place : 8772469670\n",
    "time = df_train[df_train['place_id']==8772469670]['time']\n",
    "hist = np.histogram(time,5000)\n",
    "hist_fft = np.absolute(np.fft.fft(hist[0]))\n",
    "\n",
    "plt.plot(hist_fft)\n",
    "plt.xlim([0,1000])\n",
    "plt.title('FFT of event time histogram at 1st place')\n",
    "plt.xlabel('1/T')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print \"1st period: {}, close to 10080 minutes a week.\".format(time.max() / (hist_fft[2:200].argmax()+2.0))\n",
    "print \"2nd period: {}, close to 1440 minutes a day.\".format(time.max() / (hist_fft[400:600].argmax()+400.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 2 place : 1623394281\n",
    "time = df_train[df_train['place_id']==1623394281]['time']\n",
    "hist = np.histogram(time,5000)\n",
    "hist_fft = np.absolute(np.fft.fft(hist[0]))\n",
    "\n",
    "plt.plot(hist_fft)\n",
    "plt.xlim([0,1000])\n",
    "plt.title('FFT of event time histogram at 1st place')\n",
    "plt.xlabel('1/T')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print \"1st period: {}, close to 10080 minutes a week.\".format(time.max() / (hist_fft[2:200].argmax()+2.0))\n",
    "print \"2nd period: {}, close to 1440 minutes a day.\".format(time.max() / (hist_fft[400:600].argmax()+400.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 3 place : 1308450003\n",
    "time = df_train[df_train['place_id']==1308450003]['time']\n",
    "hist = np.histogram(time,5000)\n",
    "hist_fft = np.absolute(np.fft.fft(hist[0]))\n",
    "\n",
    "plt.plot(hist_fft)\n",
    "plt.xlim([0,1000])\n",
    "plt.title('FFT of event time histogram at 1st place')\n",
    "plt.xlabel('1/T')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print \"1st period: {}, close to 10080 minutes a week.\".format(time.max() / (hist_fft[2:200].argmax()+2.0))\n",
    "print \"2nd period: {}, close to 1440 minutes a day.\".format(time.max() / (hist_fft[300:500].argmax()+300.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore small grid\n",
    "* From this section, it could be found that adding dimension of time would help seperating clusters.\n",
    "* By zooming in on the maps, I'm trying to explore the data clusters on the x and y coordinates.\n",
    "* It seems that there are some clusters could be found on the coordinates, but it still has quite overlaps.\n",
    "* Inspired by [Alexandru Papiu](https://www.kaggle.com/apapiu/facebook-v-predicting-check-ins/random-forest-on-a-few-blocks/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_grid = df_train[(df_train['x']<0.1)&(df_train['y']<0.1)]\n",
    "color = dict(zip(small_grid['place_id'].unique(), cm.rainbow(np.linspace(0,1,small_grid['place_id'].unique().shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "for place, group in small_grid.groupby('place_id'):\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', color=color[place])\n",
    "ax.set_title('Check-ins colored by place_id')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be found that the clusters are more easy to be seperated on some specific hour, because check-ins appear more often on specific hour for some specific places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1,ax2) = plt.subplots(ncols=2, sharey=True,figsize=(15,10))\n",
    "for place, group in small_grid.groupby('place_id'):\n",
    "    group.plot(ax=ax1, kind='scatter', x='x', y='hour', color=color[place])\n",
    "    group.plot(ax=ax2, kind='scatter', x='y', y='hour', color=color[place])\n",
    "ax1.set_title('Place_ids by x and hour')\n",
    "ax2.set_title('Place_ids by y and hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below histogram, we could see the check-ins on these two places are almost complement on dimension of time, one is popular at morning and the other is popular at night. This could help us double check the idea of adding the dimensio of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1,ax2) = plt.subplots(nrows=2, sharey=True,figsize=(15,10))\n",
    "df_train[df_train['place_id']==8772469670]['hour'].hist(bins=100,ax=ax1)\n",
    "ax1.set_title('Histogram of check-ins on the 1st popular place')\n",
    "ax1.set_xlabel('Hour')\n",
    "ax1.set_ylabel('Frequency')\n",
    "df_train[df_train['place_id']==1623394281]['hour'].hist(bins=100,ax=ax2)\n",
    "ax2.set_title('Histogram of check-ins on the 2nd popular place')\n",
    "ax2.set_xlabel('Hour')\n",
    "ax2.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "* Are the algorithms you will use, including any default variables/parameters in the project clearly defined?\n",
    "* Are the techniques to be used thoroughly discussed and justified?\n",
    "* Is it made clear how the input data or datasets will be handled by the algorithms and techniques chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "* Has some result or value been provided that acts as a benchmark for measuring performance?\n",
    "* Is it clear how this result or value was obtained (whether by data or by hypothesis)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Explore Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "place_ranking = df_train['place_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['log'] = np.log10(df_train['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_by_place = df_train.groupby('place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_sections = 13\n",
    "Sections = pd.cut(df_train['log'], bins=num_sections, right=False)\n",
    "data = df_train.groupby(['place_id', Sections])\n",
    "sections = Sections.values.categories.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, AX = plt.subplots(nrows=5,figsize=(15,20))\n",
    "for place,ax in zip(place_ranking.head(5).index.values, AX):   \n",
    "    data_by_place.get_group(place)['log'].hist(bins=100,ax=ax)\n",
    "    ax.set_title('Histogram of place, {}'.format(place))\n",
    "    ax.xaxis.set_ticks(np.arange(0,3,0.20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for place in place_ranking.head(5).index.values:\n",
    "    values = []\n",
    "    for section in sections:\n",
    "        try:\n",
    "            value = data.get_group((place,section))['x'].std()\n",
    "        except KeyError:\n",
    "            value = -1\n",
    "        finally:\n",
    "            values.append(value)\n",
    "    result[place] = values\n",
    "f, ax = plt.subplots(figsize=(15,10))\n",
    "pd.DataFrame(result,index=sections).plot(ax=ax)\n",
    "ax.set_xticks(range(0,13));\n",
    "ax.set_xticklabels(sections);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for place in place_ranking.head(5).index.values:\n",
    "    values = []\n",
    "    median = data_by_place.get_group(place)['x'].median()\n",
    "    for section in sections:\n",
    "        try:\n",
    "            value = np.abs(data.get_group((place,section))['x'] - median).median()\n",
    "        except KeyError:\n",
    "            value = 0\n",
    "        finally:\n",
    "            values.append(value)\n",
    "    result[place] = values\n",
    "f, ax = plt.subplots(figsize=(20,10))\n",
    "pd.DataFrame(result,index=sections).plot(ax=ax)\n",
    "ax.set_xticks(range(0,13));\n",
    "ax.set_xticklabels(sections);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.scatter(data_by_place.loc[8772469670]['x'], data_by_place.loc[8772469670]['accuracy'])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(data_by_place.loc[8772469670]['y'], data_by_place.loc[8772469670]['accuracy'])\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('accuracy')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.scatter(data_by_place.loc[1308450003]['x'], data_by_place.loc[1308450003]['accuracy'])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(data_by_place.loc[1308450003]['y'], data_by_place.loc[1308450003]['accuracy'])\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('accuracy')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "sns.regplot(x='hour',y='accuracy',data=data_by_place[data_by_place['day']==1].loc[place1],fit_reg=False,ax=ax1)\n",
    "sns.regplot(x='hour',y='accuracy',data=data_by_place[data_by_place['day']==2].loc[place1],fit_reg=False,ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "sns.regplot(x='hour',y='accuracy',data=data_by_place.loc[place1],fit_reg=False,ax=ax1)\n",
    "sns.regplot(x='day',y='accuracy',data=data_by_place.loc[place1],fit_reg=False,ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it has been found that the unit of time is minute, we could add more fields based on time, **hour, weekday, month, year**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_date = np.datetime64('2014-01-01T01:01', dtype='datetime64[m]')\n",
    "# Training data\n",
    "time = pd.DatetimeIndex(df_train['time'] + initial_date)\n",
    "df_train['hour'] = time.hour\n",
    "df_train['weekday'] = time.weekday\n",
    "df_train['day'] = time.dayofyear\n",
    "df_train['month'] = time.month\n",
    "df_train['year'] = time.year - 2013\n",
    "# Testing data\n",
    "time = pd.DatetimeIndex(df_test['time'] + initial_date)\n",
    "df_test['hour'] = time.hour\n",
    "df_test['weekday'] = time.weekday\n",
    "df_test['day'] = time.dayofyear\n",
    "df_test['month'] = time.month\n",
    "df_test['year'] = time.year - 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating Grid\n",
    "eps = 0.00001\n",
    "n_cell_x = 20\n",
    "n_cell_y = 40\n",
    "size_x = 10.0 / n_cell_x\n",
    "size_y = 10.0 / n_cell_y\n",
    "# Training data\n",
    "pos_x = (np.where(df_train['x'].values < eps, 0, df_train['x'].values - eps) / size_x).astype(int)\n",
    "pos_y = (np.where(df_train['y'].values < eps, 0, df_train['y'].values - eps) / size_y).astype(int)\n",
    "df_train['grid_cell'] = pos_y * n_cell_x + pos_x\n",
    "# Testing data\n",
    "pos_x = (np.where(df_test['x'].values < eps, 0, df_test['x'].values - eps) / size_x).astype(int)\n",
    "pos_y = (np.where(df_test['y'].values < eps, 0, df_test['y'].values - eps) / size_y).astype(int)\n",
    "df_test['grid_cell'] = pos_y * n_cell_x + pos_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "fw = {'x':500, 'y':1000, 'hour':4, 'weekday':3, 'day':1.0/22, 'month':2, 'year':10}\n",
    "# Training data\n",
    "for col in fw:\n",
    "    df_train[col] = df_train[col]*fw[col]\n",
    "# Testing data\n",
    "for col in fw:\n",
    "    df_test[col] = df_test[col]*fw[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Train each cell by KNN\n",
    "def process_one_cell(df_train, df_test, cell_id, th):\n",
    "    df_train_cell = df_train.loc[df_train['grid_cell'] == cell_id]\n",
    "    place_counts = df_train_cell['place_id'].value_counts()\n",
    "    mask = (place_counts[df_train_cell['place_id']] >= th).values\n",
    "    df_train_cell = df_train_cell.loc[mask]\n",
    "    \n",
    "    df_test_cell = df_test.loc[df_test['grid_cell'] == cell_id]\n",
    "    row_ids = df_test_cell.index\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(df_train_cell['place_id'].values)\n",
    "    X_train = df_train_cell[['x', 'y', 'hour', 'weekday', 'day', 'month', 'year']].values\n",
    "    X_test = df_test_cell[['x', 'y', 'hour', 'weekday', 'day', 'month', 'year']].values\n",
    "    \n",
    "    params = {'n_neighbors':25, 'weights':'distance', 'metric':'manhattan'}\n",
    "    clf = KNeighborsClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    # Reverse sorting and taking the top 3 place ids\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3])\n",
    "    return pred_labels, row_ids\n",
    "labels, ids = process_one_cell(df_train, df_test, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_grid(df_train, df_test, th, num_cells):\n",
    "    preds = np.zeros((df_test.shape[0], 3), dtype=int)\n",
    "    for cell_id in range(num_cells):\n",
    "        if cell_id % 50 == 0:\n",
    "            print \"Progress: {:.2f}%\".format(cell_id * 100.0 / num_cells)\n",
    "        pred_labels, row_ids = process_one_cell(df_train, df_test, cell_id, th)\n",
    "        preds[row_ids] = pred_labels\n",
    "    \n",
    "    print('Generating submission file ...')\n",
    "    df_aux = pd.DataFrame(preds, dtype=str, columns=['place1', 'place2', 'place3'])\n",
    "    ds_sub = df_aux['place1'].str.cat([df_aux['place2'], df_aux['place3']], sep=' ')\n",
    "    ds_sub.name = 'place_id'\n",
    "    ds_sub.to_csv('sub_knn.csv', index=True, header=True, index_label='row_id')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Progress: 0.00%\n",
      "Generating submission file ...\n"
     ]
    }
   ],
   "source": [
    "th = 5 \n",
    "process_grid(df_train, df_test, th, n_cell_x*n_cell_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
